# Chapter 03. 회귀 알고리즘과 모델 규제
회귀(regression)에 대해 알아보고, sklearn를 통한 머신러닝 코드 기초를 알아본다.
# 03-1. k-최근접 회귀
## 기본 코드
1. `train_test_split`로 train, test 데이터를 쉽게 나눌 수 있다.
2. numpy `reshape(a,b)` 함수로 array 크기(차원)를 조정할 수 있다. 파라미터로 `-1`을 넣으면 해당 위치의 크기를 자동으로 조절한다.
> sklearn에서는 train 데이터로 2차원 배열을 요구한다.
## 알고리즘
1. target 데이터(x)와 가장 근접한 k개의 데이터(x)의 y값 평균을 예측값으로 사용한다.
2. ```KNeighborsRegressor()```로 해당 모델을 만들 수 있다. (기본 k=3)
## 모델 평가
1. 모델 변수에 `.fit(x, y)`을 사용해 모델을 피팅하고, `.score(x,y)`를 통해 모델을 평가할 수 있다.
2. `.predict(x)`로 단일 값에 대한 예측값 y를 확인할 수 있다.
3. 결정계수($R^2$)로 모델을 평가한다.  
$R^2 = 1 - \frac{(타깃-예측)^2}{(타깃-평균)^2}$ 수식을 보면, 예측 결과가 정확할수록 1이 된다.
4. `mean_absolute_error(target, predict)`으로 절댓값 오차를 계산할 수도 있다.
## 과적합
1. train에서 충분한 학습이 되지 않을 경우 underfitting(과소적합), 너무 많이 반영될 경우 overfitting(과대적합)이 일어난다.
2. 과소적합이 일어날 경우, train 데이터를 충분히 준비하거나 모델을 더 복잡하게 하여 학습을 많이 시키면 개선될 수 있다.
3. 예제에서는 k-최근접 회귀의 k값을 3->5로 바꾸어 모델을 더 복잡하게 만들어 개선하였다.

## 03-2. 선형 회귀
